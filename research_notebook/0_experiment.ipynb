{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd196556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forensic Non-AI Detection Notebook Ready\n"
     ]
    }
   ],
   "source": [
    "# Digital Authenticity Verification System (Non-ML Forensic Engine)\n",
    "# Jupyter Notebook Prototype\n",
    "# ----------------------------------------------\n",
    "# Pure Passive Techniques | No ML | No DL | No AI\n",
    "# Focus: AI-generated image detection + tampering traces\n",
    "\n",
    "# ========== SETUP ==========\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft2, fftshift\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.filters import sobel\n",
    "import hashlib\n",
    "import exifread\n",
    "import os\n",
    "\n",
    "# ========== UTILITY FUNCTIONS ==========\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# ========== 1. NOISE RESIDUAL EXTRACTION ==========\n",
    "def extract_noise_residual(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    denoised = denoise_nl_means(gray, fast_mode=True, patch_size=5, patch_distance=6)\n",
    "    residual = gray - denoised\n",
    "    return residual\n",
    "\n",
    "# ========== 2. PRNU APPROXIMATION ==========\n",
    "def prnu_score(residual):\n",
    "    return np.std(residual)\n",
    "\n",
    "# ========== 3. CFA PATTERN CHECK ==========\n",
    "def cfa_pattern_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    h, w = gray.shape\n",
    "    pattern = gray[0:h:2, 0:w:2]\n",
    "    return np.var(pattern)\n",
    "\n",
    "# ========== 4. FREQUENCY DOMAIN ==========\n",
    "def frequency_analysis(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    f = fft2(gray)\n",
    "    fshift = fftshift(f)\n",
    "    magnitude = np.log(np.abs(fshift) + 1)\n",
    "    return magnitude\n",
    "\n",
    "# ========== 5. WAVELET ANALYSIS ==========\n",
    "def wavelet_energy(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    coeffs = pywt.wavedec2(gray, 'haar', level=2)\n",
    "    energy = 0\n",
    "    for level in coeffs[1:]:\n",
    "        for band in level:\n",
    "            energy += np.sum(np.square(band))\n",
    "    return energy\n",
    "\n",
    "# ========== 6. ENTROPY ==========\n",
    "def entropy_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist,_ = np.histogram(gray.flatten(), bins=256, density=True)\n",
    "    return entropy(hist + 1e-10)\n",
    "\n",
    "# ========== 7. EDGE NATURALNESS ==========\n",
    "def edge_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = sobel(gray)\n",
    "    return np.mean(edges)\n",
    "\n",
    "# ========== 8. TEXTURE RANDOMNESS ==========\n",
    "def texture_randomness(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return np.std(gray)\n",
    "\n",
    "# ========== 9. COMPRESSION ARTIFACT ==========\n",
    "def compression_score(path):\n",
    "    img = Image.open(path)\n",
    "    info = img.info\n",
    "    return len(info)\n",
    "\n",
    "# ========== 10. METADATA ANALYSIS ==========\n",
    "def metadata_score(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        tags = exifread.process_file(f)\n",
    "    return len(tags)\n",
    "\n",
    "# ========== AI TRACE EVIDENCE EXTRACTOR ==========\n",
    "def forensic_vector(img, path):\n",
    "    residual = extract_noise_residual(img)\n",
    "    vector = {\n",
    "        \"PRNU\": prnu_score(residual),\n",
    "        \"CFA\": cfa_pattern_score(img),\n",
    "        \"FREQ\": np.mean(frequency_analysis(img)),\n",
    "        \"WAVELET\": wavelet_energy(img),\n",
    "        \"ENTROPY\": entropy_score(img),\n",
    "        \"EDGE\": edge_score(img),\n",
    "        \"TEXTURE\": texture_randomness(img),\n",
    "        \"COMPRESSION\": compression_score(path),\n",
    "        \"METADATA\": metadata_score(path)\n",
    "    }\n",
    "    return vector\n",
    "\n",
    "# ========== RULE ENGINE ==========\n",
    "def ai_rule_engine(vector):\n",
    "    score = 0\n",
    "    if vector['PRNU'] < 5: score += 1\n",
    "    if vector['CFA'] < 10: score += 1\n",
    "    if vector['ENTROPY'] < 4: score += 1\n",
    "    if vector['FREQ'] < 5: score += 1\n",
    "    if vector['METADATA'] == 0: score += 1\n",
    "\n",
    "    if score >= 3:\n",
    "        return \"AI-GENERATED PROBABLE\"\n",
    "    else:\n",
    "        return \"NATURAL IMAGE PROBABLE\"\n",
    "\n",
    "# ========== MAIN PIPELINE ==========\n",
    "def analyze_image(path):\n",
    "    img = load_image(path)\n",
    "    vector = forensic_vector(img, path)\n",
    "    decision = ai_rule_engine(vector)\n",
    "    return vector, decision\n",
    "\n",
    "# ========== DEMO ==========\n",
    "# path = \"sample_image.jpg\"\n",
    "# vector, decision = analyze_image(path)\n",
    "# print(\"Forensic Vector:\", vector)\n",
    "# print(\"Decision:\", decision)\n",
    "\n",
    "print(\"Forensic Non-AI Detection Notebook Ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2cffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forensic Vector: {'NOISE_STD': 6.151243686676025, 'NOISE_GAUSS_P': 0.0, 'NOISE_ISOTROPY': -0.40316124454685465, 'NOISE_AUTOCORR': -362.07470703125, 'CFA_PERIOD': 0.0402933935920089, 'FREQ_MEAN': 8.39011362148339, 'FREQ_STD': 0.7759420279566878, 'DIFFUSION_SYM': 3.967069625854492, 'WAVELET': 45961877.625000015, 'ENTROPY': 5.286498376715859, 'EDGE_MEAN': 0.03124735693795944, 'EDGE_STD': 0.06139321941040066, 'TEXTURE': 51.3220127851486, 'METADATA': 0}\n",
      "Decision: AI-GENERATED PROBABLE\n"
     ]
    }
   ],
   "source": [
    "# path = \"data/Gemini_Generated_Image_ghhom5ghhom5ghho (1).png\"\n",
    "# vector, decision = analyze_image(path)\n",
    "\n",
    "# print(\"Forensic Vector:\", vector)\n",
    "# print(\"Decision:\", decision)\n",
    "\n",
    "path = \"data/0bdadc14-d5d3-40ca-a6df-47efe2e988cc.jpg\"\n",
    "vector, decision,score = analyze_image(path)\n",
    "\n",
    "print(\"Forensic Vector:\", vector)\n",
    "print(\"Decision:\", decision)\n",
    "# print(\"score\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba570f",
   "metadata": {},
   "source": [
    "V2  upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1692968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPGRADED Forensic AI Detection Notebook Ready\n"
     ]
    }
   ],
   "source": [
    "# Digital Authenticity Verification System (Non-ML Forensic Engine)\n",
    "# Jupyter Notebook Prototype (UPGRADED v2)\n",
    "# ----------------------------------------------\n",
    "# Pure Passive Techniques | No ML | No DL | No AI\n",
    "# Focus: AI-generated image detection + tampering traces\n",
    "# Includes: Synthetic noise detection, diffusion traces, physics-based validation\n",
    "\n",
    "# ========== SETUP ==========\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft2, fftshift\n",
    "from scipy.stats import entropy, normaltest\n",
    "from scipy.signal import correlate2d\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.filters import sobel\n",
    "import exifread\n",
    "import os\n",
    "\n",
    "# ========== UTILITY FUNCTIONS ==========\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# ========== NOISE RESIDUAL ==========\n",
    "def extract_noise_residual(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    denoised = denoise_nl_means(gray, fast_mode=True, patch_size=5, patch_distance=6)\n",
    "    residual = gray - denoised\n",
    "    return residual\n",
    "\n",
    "# ========== NOISE STRUCTURE ANALYSIS ==========\n",
    "def noise_gaussian_test(residual):\n",
    "    stat, p = normaltest(residual.flatten())\n",
    "    return p  # low p = non-natural\n",
    "\n",
    "def noise_isotropy(residual):\n",
    "    gradx = cv2.Sobel(residual, cv2.CV_64F, 1, 0)\n",
    "    grady = cv2.Sobel(residual, cv2.CV_64F, 0, 1)\n",
    "    return np.std(gradx) - np.std(grady)\n",
    "\n",
    "\n",
    "def noise_autocorrelation(residual):\n",
    "    corr = correlate2d(residual, residual, mode='same')\n",
    "    center = corr[corr.shape[0]//2, corr.shape[1]//2]\n",
    "    return center / (np.mean(corr)+1e-8)\n",
    "\n",
    "# ========== CFA PERIODICITY ==========\n",
    "def cfa_periodicity(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    even = gray[0::2, 0::2]\n",
    "    odd = gray[1::2, 1::2]\n",
    "    return abs(np.mean(even) - np.mean(odd))\n",
    "\n",
    "# ========== FREQUENCY DOMAIN ==========\n",
    "def frequency_spectrum(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    f = fft2(gray)\n",
    "    fshift = fftshift(f)\n",
    "    mag = np.log(np.abs(fshift)+1)\n",
    "    return np.mean(mag), np.std(mag)\n",
    "\n",
    "# ========== DIFFUSION TRACE ==========\n",
    "def diffusion_trace(residual):\n",
    "    # symmetry + isotropy indicator\n",
    "    h, w = residual.shape\n",
    "    left = residual[:, :w//2]\n",
    "    right = np.fliplr(residual[:, w//2:])\n",
    "    sym = np.mean(np.abs(left - right[:,:left.shape[1]]))\n",
    "    return sym\n",
    "\n",
    "# ========== WAVELET ENERGY ==========\n",
    "def wavelet_energy(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    coeffs = pywt.wavedec2(gray, 'haar', level=2)\n",
    "    energy = 0\n",
    "    for level in coeffs[1:]:\n",
    "        for band in level:\n",
    "            energy += np.sum(np.square(band))\n",
    "    return energy\n",
    "\n",
    "# ========== ENTROPY ==========\n",
    "def entropy_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist,_ = np.histogram(gray.flatten(), bins=256, density=True)\n",
    "    return entropy(hist + 1e-10)\n",
    "\n",
    "# ========== EDGE NATURALNESS ==========\n",
    "def edge_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = sobel(gray)\n",
    "    return np.mean(edges), np.std(edges)\n",
    "\n",
    "# ========== TEXTURE RANDOMNESS ==========\n",
    "def texture_randomness(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return np.std(gray)\n",
    "\n",
    "# ========== METADATA ==========\n",
    "def metadata_score(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            tags = exifread.process_file(f)\n",
    "        return len(tags)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ========== FORENSIC VECTOR ==========\n",
    "def forensic_vector(img, path):\n",
    "    residual = extract_noise_residual(img)\n",
    "    freq_mean, freq_std = frequency_spectrum(img)\n",
    "    edge_mean, edge_std = edge_score(img)\n",
    "\n",
    "    vector = {\n",
    "        \"NOISE_STD\": float(np.std(residual)),\n",
    "        \"NOISE_GAUSS_P\": float(noise_gaussian_test(residual)),\n",
    "        \"NOISE_ISOTROPY\": float(noise_isotropy(residual)),\n",
    "        \"NOISE_AUTOCORR\": float(noise_autocorrelation(residual)),\n",
    "        \"CFA_PERIOD\": float(cfa_periodicity(img)),\n",
    "        \"FREQ_MEAN\": float(freq_mean),\n",
    "        \"FREQ_STD\": float(freq_std),\n",
    "        \"DIFFUSION_SYM\": float(diffusion_trace(residual)),\n",
    "        \"WAVELET\": float(wavelet_energy(img)),\n",
    "        \"ENTROPY\": float(entropy_score(img)),\n",
    "        \"EDGE_MEAN\": float(edge_mean),\n",
    "        \"EDGE_STD\": float(edge_std),\n",
    "        \"TEXTURE\": float(texture_randomness(img)),\n",
    "        \"METADATA\": int(metadata_score(path))\n",
    "    }\n",
    "    return vector\n",
    "\n",
    "# ========== UPGRADED RULE ENGINE ==========\n",
    "def ai_rule_engine(vector):\n",
    "    ai_score = 0\n",
    "\n",
    "    # Synthetic noise detection\n",
    "    if vector['NOISE_GAUSS_P'] > 0.05: ai_score += 1\n",
    "    if abs(vector['NOISE_ISOTROPY']) < 0.5: ai_score += 1\n",
    "    if vector['NOISE_AUTOCORR'] > 1.5: ai_score += 1\n",
    "\n",
    "    # CFA physics\n",
    "    if vector['CFA_PERIOD'] < 2: ai_score += 1\n",
    "\n",
    "    # Diffusion symmetry\n",
    "    if vector['DIFFUSION_SYM'] < 5: ai_score += 1\n",
    "\n",
    "    # Entropy unnatural uniformity\n",
    "    if vector['ENTROPY'] > 5.0: ai_score += 1\n",
    "\n",
    "    # Metadata absence\n",
    "    if vector['METADATA'] == 0: ai_score += 1\n",
    "\n",
    "    if ai_score >= 4:\n",
    "        return \"AI-GENERATED PROBABLE\", ai_score\n",
    "    elif ai_score == 3:\n",
    "        return \"SUSPICIOUS / HYBRID\", ai_score\n",
    "    else:\n",
    "        return \"NATURAL IMAGE PROBABLE\", ai_score\n",
    "\n",
    "# ========== MAIN PIPELINE ==========\n",
    "def analyze_image(path):\n",
    "    img = load_image(path)\n",
    "    vector = forensic_vector(img, path)\n",
    "    decision, score = ai_rule_engine(vector)\n",
    "    return vector, decision, score\n",
    "\n",
    "# ========== VISUALIZATION ==========\n",
    "def visualize_forensics(path):\n",
    "    img = load_image(path)\n",
    "    residual = extract_noise_residual(img)\n",
    "    freq = fftshift(fft2(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)))\n",
    "    mag = np.log(np.abs(freq)+1)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Noise Residual')\n",
    "    plt.imshow(residual, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Frequency Spectrum')\n",
    "    plt.imshow(mag, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ========== DEMO ==========\n",
    "# path = \"sample_image.png\"\n",
    "# vector, decision, score = analyze_image(path)\n",
    "# print(\"Forensic Vector:\\n\", vector)\n",
    "# print(\"Decision:\", decision)\n",
    "# print(\"AI Evidence Score:\", score)\n",
    "# visualize_forensics(path)\n",
    "\n",
    "print(\"UPGRADED Forensic AI Detection Notebook Ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d458d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Gemini_Generated_Image_ghhom5ghhom5ghho (1).png\"\n",
    "vector, decision = analyze_image(path)\n",
    "\n",
    "print(\"Forensic Vector:\", vector)\n",
    "print(\"Decision:\", decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ca77e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST Forensic AI Detection Notebook Ready\n"
     ]
    }
   ],
   "source": [
    "# Digital Authenticity Verification System (Non-ML Forensic Engine)\n",
    "# Jupyter Notebook Prototype (UPGRADED v3 - FAST VERSION)\n",
    "# ----------------------------------------------\n",
    "# Pure Passive Techniques | No ML | No DL | No AI\n",
    "# Optimized for performance (no hanging, fast execution)\n",
    "# Focus: AI-generated image detection + tampering traces\n",
    "\n",
    "# ========== SETUP ==========\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft2, fftshift\n",
    "from scipy.stats import entropy, normaltest\n",
    "from scipy.signal import correlate2d\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import sobel\n",
    "import exifread\n",
    "\n",
    "# ========== UTILITY FUNCTIONS ==========\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# ========== FAST NOISE RESIDUAL ==========\n",
    "def extract_noise_residual(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    denoised = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    residual = gray.astype(np.float32) - denoised.astype(np.float32)\n",
    "    return residual\n",
    "\n",
    "# ========== NOISE STRUCTURE ANALYSIS ==========\n",
    "def noise_gaussian_test(residual):\n",
    "    sample = residual.flatten()[::50]  # subsample\n",
    "    stat, p = normaltest(sample)\n",
    "    return p\n",
    "\n",
    "\n",
    "def noise_isotropy(residual):\n",
    "    gradx = cv2.Sobel(residual, cv2.CV_64F, 1, 0)\n",
    "    grady = cv2.Sobel(residual, cv2.CV_64F, 0, 1)\n",
    "    return np.std(gradx) - np.std(grady)\n",
    "\n",
    "\n",
    "def noise_autocorrelation(residual):\n",
    "    small = cv2.resize(residual, (128,128))\n",
    "    corr = correlate2d(small, small, mode='same')\n",
    "    center = corr[corr.shape[0]//2, corr.shape[1]//2]\n",
    "    return center / (np.mean(corr)+1e-8)\n",
    "\n",
    "# ========== CFA PERIODICITY ==========\n",
    "def cfa_periodicity(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    even = gray[0::2, 0::2]\n",
    "    odd = gray[1::2, 1::2]\n",
    "    return abs(np.mean(even) - np.mean(odd))\n",
    "\n",
    "# ========== FREQUENCY DOMAIN ==========\n",
    "def frequency_spectrum(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, (256,256))\n",
    "    f = fft2(gray)\n",
    "    fshift = fftshift(f)\n",
    "    mag = np.log(np.abs(fshift)+1)\n",
    "    return np.mean(mag), np.std(mag)\n",
    "\n",
    "# ========== DIFFUSION TRACE ==========\n",
    "def diffusion_trace(residual):\n",
    "    small = cv2.resize(residual, (128,128))\n",
    "    h, w = small.shape\n",
    "    left = small[:, :w//2]\n",
    "    right = np.fliplr(small[:, w//2:])\n",
    "    sym = np.mean(np.abs(left - right[:,:left.shape[1]]))\n",
    "    return sym\n",
    "\n",
    "# ========== WAVELET ENERGY ==========\n",
    "def wavelet_energy(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, (256,256))\n",
    "    coeffs = pywt.wavedec2(gray, 'haar', level=2)\n",
    "    energy = 0\n",
    "    for level in coeffs[1:]:\n",
    "        for band in level:\n",
    "            energy += np.sum(np.square(band))\n",
    "    return energy\n",
    "\n",
    "# ========== ENTROPY ==========\n",
    "def entropy_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist,_ = np.histogram(gray.flatten(), bins=256, density=True)\n",
    "    return entropy(hist + 1e-10)\n",
    "\n",
    "# ========== EDGE NATURALNESS ==========\n",
    "def edge_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = sobel(gray)\n",
    "    return np.mean(edges), np.std(edges)\n",
    "\n",
    "# ========== TEXTURE RANDOMNESS ==========\n",
    "def texture_randomness(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return np.std(gray)\n",
    "\n",
    "# ========== METADATA ==========\n",
    "def metadata_score(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            tags = exifread.process_file(f)\n",
    "        return len(tags)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ========== FORENSIC VECTOR ==========\n",
    "def forensic_vector(img, path):\n",
    "    residual = extract_noise_residual(img)\n",
    "    freq_mean, freq_std = frequency_spectrum(img)\n",
    "    edge_mean, edge_std = edge_score(img)\n",
    "\n",
    "    vector = {\n",
    "        \"NOISE_STD\": float(np.std(residual)),\n",
    "        \"NOISE_GAUSS_P\": float(noise_gaussian_test(residual)),\n",
    "        \"NOISE_ISOTROPY\": float(noise_isotropy(residual)),\n",
    "        \"NOISE_AUTOCORR\": float(noise_autocorrelation(residual)),\n",
    "        \"CFA_PERIOD\": float(cfa_periodicity(img)),\n",
    "        \"FREQ_MEAN\": float(freq_mean),\n",
    "        \"FREQ_STD\": float(freq_std),\n",
    "        \"DIFFUSION_SYM\": float(diffusion_trace(residual)),\n",
    "        \"WAVELET\": float(wavelet_energy(img)),\n",
    "        \"ENTROPY\": float(entropy_score(img)),\n",
    "        \"EDGE_MEAN\": float(edge_mean),\n",
    "        \"EDGE_STD\": float(edge_std),\n",
    "        \"TEXTURE\": float(texture_randomness(img)),\n",
    "        \"METADATA\": int(metadata_score(path))\n",
    "    }\n",
    "    return vector\n",
    "\n",
    "# ========== RULE ENGINE ==========\n",
    "def ai_rule_engine(vector):\n",
    "    ai_score = 0\n",
    "\n",
    "    # Synthetic noise detection\n",
    "    if vector['NOISE_GAUSS_P'] > 0.05: ai_score += 1\n",
    "    if abs(vector['NOISE_ISOTROPY']) < 0.5: ai_score += 1\n",
    "    if vector['NOISE_AUTOCORR'] > 1.2: ai_score += 1\n",
    "\n",
    "    # CFA physics\n",
    "    if vector['CFA_PERIOD'] < 2: ai_score += 1\n",
    "\n",
    "    # Diffusion symmetry\n",
    "    if vector['DIFFUSION_SYM'] < 5: ai_score += 1\n",
    "\n",
    "    # Entropy uniformity\n",
    "    if vector['ENTROPY'] > 5.0: ai_score += 1\n",
    "\n",
    "    # Metadata absence\n",
    "    if vector['METADATA'] == 0: ai_score += 1\n",
    "\n",
    "    if ai_score >= 4:\n",
    "        return \"AI-GENERATED PROBABLE\", ai_score\n",
    "    elif ai_score == 3:\n",
    "        return \"SUSPICIOUS / HYBRID\", ai_score\n",
    "    else:\n",
    "        return \"NATURAL IMAGE PROBABLE\", ai_score\n",
    "\n",
    "# ========== MAIN PIPELINE ==========\n",
    "def analyze_image(path):\n",
    "    img = load_image(path)\n",
    "    vector = forensic_vector(img, path)\n",
    "    decision, score = ai_rule_engine(vector)\n",
    "    return vector, decision, score\n",
    "\n",
    "# ========== VISUALIZATION ==========\n",
    "def visualize_forensics(path):\n",
    "    img = load_image(path)\n",
    "    residual = extract_noise_residual(img)\n",
    "    freq = fftshift(fft2(cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY),(256,256))))\n",
    "    mag = np.log(np.abs(freq)+1)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Noise Residual')\n",
    "    plt.imshow(residual, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Frequency Spectrum')\n",
    "    plt.imshow(mag, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ========== DEMO ==========\n",
    "# path = \"sample_image.png\"\n",
    "# vector, decision, score = analyze_image(path)\n",
    "# print(\"Forensic Vector:\\n\", vector)\n",
    "# print(\"Decision:\", decision)\n",
    "# print(\"AI Evidence Score:\", score)\n",
    "# visualize_forensics(path)\n",
    "\n",
    "print(\"FAST Forensic AI Detection Notebook Ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf49009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PNG file does not have exif data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forensic Vector: {'NOISE_STD': 14.186527252197266, 'NOISE_GAUSS_P': 0.0, 'NOISE_ISOTROPY': -5.783599204693459, 'NOISE_AUTOCORR': -256.0876770019531, 'CFA_PERIOD': 0.05436686686687153, 'FREQ_MEAN': 8.130780341362563, 'FREQ_STD': 0.8221918810582814, 'DIFFUSION_SYM': 8.122030258178711, 'WAVELET': 32899201.00000001, 'ENTROPY': 5.225854069765997, 'EDGE_MEAN': 0.048456054834449015, 'EDGE_STD': 0.08685371634367815, 'TEXTURE': 48.23144517846562, 'METADATA': 0}\n",
      "Decision: SUSPICIOUS / HYBRID\n",
      "score 3\n"
     ]
    }
   ],
   "source": [
    "path = \"data/Gemini_Generated_Image_ghhom5ghhom5ghho (1).png\"\n",
    "vector, decision, score = analyze_image(path)\n",
    "\n",
    "print(\"Forensic Vector:\", vector)\n",
    "print(\"Decision:\", decision)\n",
    "print(\"score\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5773cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forensic Vector: {'NOISE_STD': 6.151243686676025, 'NOISE_GAUSS_P': 0.0, 'NOISE_ISOTROPY': -0.40316124454685465, 'NOISE_AUTOCORR': -362.07470703125, 'CFA_PERIOD': 0.0402933935920089, 'FREQ_MEAN': 8.39011362148339, 'FREQ_STD': 0.7759420279566878, 'DIFFUSION_SYM': 3.967069625854492, 'WAVELET': 45961877.625000015, 'ENTROPY': 5.286498376715859, 'EDGE_MEAN': 0.03124735693795944, 'EDGE_STD': 0.06139321941040066, 'TEXTURE': 51.3220127851486, 'METADATA': 0}\n",
      "Decision: AI-GENERATED PROBABLE\n",
      "score 5\n"
     ]
    }
   ],
   "source": [
    "path = \"data/0bdadc14-d5d3-40ca-a6df-47efe2e988cc.jpg\"\n",
    "vector, decision, score = analyze_image(path)\n",
    "\n",
    "print(\"Forensic Vector:\", vector)\n",
    "print(\"Decision:\", decision)\n",
    "print(\"score\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b232c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forensic Vector: {'NOISE_STD': 18.924880981445312, 'NOISE_GAUSS_P': 0.0, 'NOISE_ISOTROPY': -7.528024462285458, 'NOISE_AUTOCORR': -12.238502502441406, 'CFA_PERIOD': 0.043505882352945946, 'FREQ_MEAN': 8.759412554907755, 'FREQ_STD': 0.7556607795851804, 'DIFFUSION_SYM': 7.3177900314331055, 'WAVELET': 119076597.75000003, 'ENTROPY': 2.3535618524709823, 'EDGE_MEAN': 0.05342950344694411, 'EDGE_STD': 0.15567829220704502, 'TEXTURE': 58.433159725179394, 'METADATA': 0}\n",
      "Decision: NATURAL IMAGE PROBABLE\n",
      "score 2\n"
     ]
    }
   ],
   "source": [
    "path = \"data/2e84308f-74ac-43c1-8c73-0ec847e51573_synthetic_inpainting_blur.jpg\"\n",
    "vector, decision, score = analyze_image(path)\n",
    "\n",
    "print(\"Forensic Vector:\", vector)\n",
    "print(\"Decision:\", decision)\n",
    "print(\"score\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "927b6c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forensic Vector: {'NOISE_STD': 19.043020248413086, 'NOISE_GAUSS_P': 0.0, 'NOISE_ISOTROPY': -5.935119403082695, 'NOISE_AUTOCORR': -6.884185314178467, 'CFA_PERIOD': 0.04253582887699281, 'FREQ_MEAN': 8.791192823760548, 'FREQ_STD': 0.7486986317470912, 'DIFFUSION_SYM': 7.484461307525635, 'WAVELET': 125231282.37500003, 'ENTROPY': 2.343287360171286, 'EDGE_MEAN': 0.054871019694383204, 'EDGE_STD': 0.15778296981651332, 'TEXTURE': 59.23668991813584, 'METADATA': 0}\n",
      "Decision: NATURAL IMAGE PROBABLE\n",
      "score 2\n"
     ]
    }
   ],
   "source": [
    "path = \"data/2e84308f-74ac-43c1-8c73-0ec847e51573.jpg\"\n",
    "vector, decision, score = analyze_image(path)\n",
    "\n",
    "print(\"Forensic Vector:\", vector)\n",
    "print(\"Decision:\", decision)\n",
    "print(\"score\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3902d",
   "metadata": {},
   "source": [
    "BatchProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85936fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
