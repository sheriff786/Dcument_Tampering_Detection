{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digital Authenticity Verification System (Non-ML Forensic Engine)\n",
    "# Jupyter Notebook Prototype (v4 - FULL FORENSIC SYSTEM)\n",
    "# -----------------------------------------------------\n",
    "# Multi-class classification + Heatmaps + Risk Score + Report Generator\n",
    "# Pure Passive Techniques | No ML | No DL | No AI\n",
    "\n",
    "# ================= SETUP =================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft2, fftshift\n",
    "from scipy.stats import entropy, normaltest\n",
    "from scipy.signal import correlate2d\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import sobel\n",
    "import exifread\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ================= UTILITIES =================\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# ================= FAST NOISE =================\n",
    "def extract_noise_residual(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    denoised = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    return gray.astype(np.float32) - denoised.astype(np.float32)\n",
    "\n",
    "# ================= FORENSIC FEATURES =================\n",
    "def noise_gaussian_test(residual):\n",
    "    sample = residual.flatten()[::50]\n",
    "    _, p = normaltest(sample)\n",
    "    return p\n",
    "\n",
    "\n",
    "def noise_isotropy(residual):\n",
    "    gradx = cv2.Sobel(residual, cv2.CV_64F, 1, 0)\n",
    "    grady = cv2.Sobel(residual, cv2.CV_64F, 0, 1)\n",
    "    return np.std(gradx) - np.std(grady)\n",
    "\n",
    "\n",
    "def noise_autocorrelation(residual):\n",
    "    small = cv2.resize(residual, (128,128))\n",
    "    corr = correlate2d(small, small, mode='same')\n",
    "    center = corr[corr.shape[0]//2, corr.shape[1]//2]\n",
    "    return center / (np.mean(corr)+1e-8)\n",
    "\n",
    "\n",
    "def cfa_periodicity(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    even = gray[0::2, 0::2]\n",
    "    odd = gray[1::2, 1::2]\n",
    "    return abs(np.mean(even) - np.mean(odd))\n",
    "\n",
    "\n",
    "def frequency_spectrum(img):\n",
    "    gray = cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY),(256,256))\n",
    "    f = fft2(gray)\n",
    "    mag = np.log(np.abs(fftshift(f))+1)\n",
    "    return np.mean(mag), np.std(mag)\n",
    "\n",
    "\n",
    "def diffusion_trace(residual):\n",
    "    small = cv2.resize(residual,(128,128))\n",
    "    h,w = small.shape\n",
    "    left = small[:, :w//2]\n",
    "    right = np.fliplr(small[:, w//2:])\n",
    "    return np.mean(np.abs(left - right[:,:left.shape[1]]))\n",
    "\n",
    "\n",
    "def wavelet_energy(img):\n",
    "    gray = cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY),(256,256))\n",
    "    coeffs = pywt.wavedec2(gray,'haar',level=2)\n",
    "    return sum(np.sum(np.square(b)) for lvl in coeffs[1:] for b in lvl)\n",
    "\n",
    "\n",
    "def entropy_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist,_ = np.histogram(gray.flatten(),bins=256,density=True)\n",
    "    return entropy(hist+1e-10)\n",
    "\n",
    "\n",
    "def edge_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = sobel(gray)\n",
    "    return np.mean(edges), np.std(edges)\n",
    "\n",
    "\n",
    "def texture_randomness(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return np.std(gray)\n",
    "\n",
    "\n",
    "def metadata_score(path):\n",
    "    try:\n",
    "        with open(path,'rb') as f:\n",
    "            tags = exifread.process_file(f)\n",
    "        return len(tags)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ================= FEATURE VECTOR =================\n",
    "def forensic_vector(img,path):\n",
    "    residual = extract_noise_residual(img)\n",
    "    fmean,fstd = frequency_spectrum(img)\n",
    "    emean,estd = edge_score(img)\n",
    "\n",
    "    return {\n",
    "        \"NOISE_STD\": float(np.std(residual)),\n",
    "        \"NOISE_GAUSS_P\": float(noise_gaussian_test(residual)),\n",
    "        \"NOISE_ISOTROPY\": float(noise_isotropy(residual)),\n",
    "        \"NOISE_AUTOCORR\": float(noise_autocorrelation(residual)),\n",
    "        \"CFA_PERIOD\": float(cfa_periodicity(img)),\n",
    "        \"FREQ_MEAN\": float(fmean),\n",
    "        \"FREQ_STD\": float(fstd),\n",
    "        \"DIFFUSION_SYM\": float(diffusion_trace(residual)),\n",
    "        \"WAVELET\": float(wavelet_energy(img)),\n",
    "        \"ENTROPY\": float(entropy_score(img)),\n",
    "        \"EDGE_MEAN\": float(emean),\n",
    "        \"EDGE_STD\": float(estd),\n",
    "        \"TEXTURE\": float(texture_randomness(img)),\n",
    "        \"METADATA\": int(metadata_score(path))\n",
    "    }\n",
    "\n",
    "# ================= MULTI-CLASS RULE ENGINE =================\n",
    "def multi_class_engine(v):\n",
    "    ai = 0\n",
    "    tamper = 0\n",
    "\n",
    "    # AI indicators\n",
    "    if v['NOISE_GAUSS_P'] > 0.05: ai+=1\n",
    "    if abs(v['NOISE_ISOTROPY']) < 0.5: ai+=1\n",
    "    if v['CFA_PERIOD'] < 2: ai+=1\n",
    "    if v['DIFFUSION_SYM'] < 5: ai+=1\n",
    "    if v['METADATA'] == 0: ai+=1\n",
    "\n",
    "    # Tamper indicators\n",
    "    if v['EDGE_STD'] > 0.08: tamper+=1\n",
    "    if v['FREQ_STD'] > 1.0: tamper+=1\n",
    "    if v['ENTROPY'] > 5.1: tamper+=1\n",
    "\n",
    "    # Classification\n",
    "    if ai>=4 and tamper<=1:\n",
    "        cls = \"AI-GENERATED\"\n",
    "    elif tamper>=3 and ai<=1:\n",
    "        cls = \"TAMPERED\"\n",
    "    elif ai>=2 and tamper>=2:\n",
    "        cls = \"HYBRID\"\n",
    "    else:\n",
    "        cls = \"NATURAL\"\n",
    "\n",
    "    return cls, ai, tamper\n",
    "\n",
    "# ================= RISK SCORE =================\n",
    "def fraud_risk_score(ai,tamper):\n",
    "    score = ai*15 + tamper*12\n",
    "    return min(score,100)\n",
    "\n",
    "# ================= HEATMAP =================\n",
    "def region_heatmap(path, grid=8):\n",
    "    img = load_image(path)\n",
    "    h,w,_ = img.shape\n",
    "    heat = np.zeros((grid,grid))\n",
    "\n",
    "    for i in range(grid):\n",
    "        for j in range(grid):\n",
    "            y1 = int(i*h/grid); y2 = int((i+1)*h/grid)\n",
    "            x1 = int(j*w/grid); x2 = int((j+1)*w/grid)\n",
    "            patch = img[y1:y2,x1:x2]\n",
    "            res = extract_noise_residual(patch)\n",
    "            heat[i,j] = np.std(res)\n",
    "\n",
    "    heat = cv2.resize(heat,(w,h))\n",
    "    return heat\n",
    "\n",
    "# ================= REPORT GENERATOR =================\n",
    "def generate_report(path,vector,cls,ai,tamper,risk):\n",
    "    report = {\n",
    "        \"file\": path,\n",
    "        \"timestamp\": str(datetime.now()),\n",
    "        \"classification\": cls,\n",
    "        \"ai_score\": ai,\n",
    "        \"tamper_score\": tamper,\n",
    "        \"fraud_risk\": risk,\n",
    "        \"forensic_vector\": vector\n",
    "    }\n",
    "\n",
    "    name = path.split('/')[-1].split('.')[0]\n",
    "    with open(f\"{name}_forensic_report.json\",\"w\") as f:\n",
    "        json.dump(report,f,indent=4)\n",
    "\n",
    "    return report\n",
    "\n",
    "# ================= PIPELINE =================\n",
    "def full_forensic_pipeline(path):\n",
    "    img = load_image(path)\n",
    "    vector = forensic_vector(img,path)\n",
    "    cls, ai, tamper = multi_class_engine(vector)\n",
    "    risk = fraud_risk_score(ai,tamper)\n",
    "    heat = region_heatmap(path)\n",
    "    report = generate_report(path,vector,cls,ai,tamper,risk)\n",
    "    return vector, cls, ai, tamper, risk, heat, report\n",
    "\n",
    "# ================= VISUAL =================\n",
    "def visualize_all(path, heat):\n",
    "    img = load_image(path)\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('AI/Tamper Heatmap')\n",
    "    plt.imshow(heat, cmap='hot')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Overlay')\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(heat, cmap='hot', alpha=0.4)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"FULL FORENSIC SYSTEM READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Gemini_Generated_Image_ghhom5ghhom5ghho (1).jpg\"\n",
    "\n",
    "vector, cls, ai, tamper, risk, heat, report = full_forensic_pipeline(path)\n",
    "\n",
    "print(\"Classification:\", cls)\n",
    "print(\"AI Score:\", ai)\n",
    "print(\"Tamper Score:\", tamper)\n",
    "print(\"Fraud Risk:\", risk)\n",
    "print(\"Report File Generated\")\n",
    "\n",
    "visualize_all(path, heat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a547d",
   "metadata": {},
   "source": [
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digital Authenticity Verification System (Non-ML Forensic Engine)\n",
    "# Jupyter Notebook Prototype (v4 - FULL FORENSIC SYSTEM)\n",
    "# -----------------------------------------------------\n",
    "# Multi-class classification + Heatmaps + Risk Score + Report Generator\n",
    "# Pure Passive Techniques | No ML | No DL | No AI\n",
    "\n",
    "# ================= SETUP =================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft2, fftshift\n",
    "from scipy.stats import entropy, normaltest\n",
    "from scipy.signal import correlate2d\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import sobel\n",
    "import exifread\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ================= UTILITIES =================\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# ================= FAST NOISE =================\n",
    "def extract_noise_residual(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    denoised = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    return gray.astype(np.float32) - denoised.astype(np.float32)\n",
    "\n",
    "# ================= FORENSIC FEATURES =================\n",
    "def noise_gaussian_test(residual):\n",
    "    sample = residual.flatten()[::50]\n",
    "    _, p = normaltest(sample)\n",
    "    return p\n",
    "\n",
    "\n",
    "def noise_isotropy(residual):\n",
    "    gradx = cv2.Sobel(residual, cv2.CV_64F, 1, 0)\n",
    "    grady = cv2.Sobel(residual, cv2.CV_64F, 0, 1)\n",
    "    return np.std(gradx) - np.std(grady)\n",
    "\n",
    "\n",
    "def noise_autocorrelation(residual):\n",
    "    small = cv2.resize(residual, (128,128))\n",
    "    corr = correlate2d(small, small, mode='same')\n",
    "    center = corr[corr.shape[0]//2, corr.shape[1]//2]\n",
    "    return center / (np.mean(corr)+1e-8)\n",
    "\n",
    "\n",
    "def cfa_periodicity(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    even = gray[0::2, 0::2]\n",
    "    odd = gray[1::2, 1::2]\n",
    "    return abs(np.mean(even) - np.mean(odd))\n",
    "\n",
    "\n",
    "def frequency_spectrum(img):\n",
    "    gray = cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY),(256,256))\n",
    "    f = fft2(gray)\n",
    "    mag = np.log(np.abs(fftshift(f))+1)\n",
    "    return np.mean(mag), np.std(mag)\n",
    "\n",
    "\n",
    "def diffusion_trace(residual):\n",
    "    small = cv2.resize(residual,(128,128))\n",
    "    h,w = small.shape\n",
    "    left = small[:, :w//2]\n",
    "    right = np.fliplr(small[:, w//2:])\n",
    "    return np.mean(np.abs(left - right[:,:left.shape[1]]))\n",
    "\n",
    "\n",
    "def wavelet_energy(img):\n",
    "    gray = cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY),(256,256))\n",
    "    coeffs = pywt.wavedec2(gray,'haar',level=2)\n",
    "    return sum(np.sum(np.square(b)) for lvl in coeffs[1:] for b in lvl)\n",
    "\n",
    "\n",
    "def entropy_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist,_ = np.histogram(gray.flatten(),bins=256,density=True)\n",
    "    return entropy(hist+1e-10)\n",
    "\n",
    "\n",
    "def edge_score(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = sobel(gray)\n",
    "    return np.mean(edges), np.std(edges)\n",
    "\n",
    "\n",
    "def texture_randomness(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return np.std(gray)\n",
    "\n",
    "\n",
    "def metadata_score(path):\n",
    "    try:\n",
    "        with open(path,'rb') as f:\n",
    "            tags = exifread.process_file(f)\n",
    "        return len(tags)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ================= FEATURE VECTOR =================\n",
    "def forensic_vector(img,path):\n",
    "    residual = extract_noise_residual(img)\n",
    "    fmean,fstd = frequency_spectrum(img)\n",
    "    emean,estd = edge_score(img)\n",
    "\n",
    "    return {\n",
    "        \"NOISE_STD\": float(np.std(residual)),\n",
    "        \"NOISE_GAUSS_P\": float(noise_gaussian_test(residual)),\n",
    "        \"NOISE_ISOTROPY\": float(noise_isotropy(residual)),\n",
    "        \"NOISE_AUTOCORR\": float(noise_autocorrelation(residual)),\n",
    "        \"CFA_PERIOD\": float(cfa_periodicity(img)),\n",
    "        \"FREQ_MEAN\": float(fmean),\n",
    "        \"FREQ_STD\": float(fstd),\n",
    "        \"DIFFUSION_SYM\": float(diffusion_trace(residual)),\n",
    "        \"WAVELET\": float(wavelet_energy(img)),\n",
    "        \"ENTROPY\": float(entropy_score(img)),\n",
    "        \"EDGE_MEAN\": float(emean),\n",
    "        \"EDGE_STD\": float(estd),\n",
    "        \"TEXTURE\": float(texture_randomness(img)),\n",
    "        \"METADATA\": int(metadata_score(path))\n",
    "    }\n",
    "\n",
    "# ================= MULTI-CLASS RULE ENGINE =================\n",
    "def multi_class_engine(v):\n",
    "    ai = 0\n",
    "    tamper = 0\n",
    "\n",
    "    # AI indicators\n",
    "    if v['NOISE_GAUSS_P'] > 0.05: ai+=1\n",
    "    if abs(v['NOISE_ISOTROPY']) < 0.5: ai+=1\n",
    "    if v['CFA_PERIOD'] < 2: ai+=1\n",
    "    if v['DIFFUSION_SYM'] < 5: ai+=1\n",
    "    if v['METADATA'] == 0: ai+=1\n",
    "\n",
    "    # Tamper indicators\n",
    "    if v['EDGE_STD'] > 0.08: tamper+=1\n",
    "    if v['FREQ_STD'] > 1.0: tamper+=1\n",
    "    if v['ENTROPY'] > 5.1: tamper+=1\n",
    "\n",
    "    # Classification\n",
    "    if ai>=4 and tamper<=1:\n",
    "        cls = \"AI-GENERATED\"\n",
    "    elif tamper>=3 and ai<=1:\n",
    "        cls = \"TAMPERED\"\n",
    "    elif ai>=2 and tamper>=2:\n",
    "        cls = \"HYBRID\"\n",
    "    else:\n",
    "        cls = \"NATURAL\"\n",
    "\n",
    "    return cls, ai, tamper\n",
    "\n",
    "# ================= RISK SCORE =================\n",
    "def fraud_risk_score(ai,tamper):\n",
    "    score = ai*15 + tamper*12\n",
    "    return min(score,100)\n",
    "\n",
    "# ================= HEATMAP =================\n",
    "def region_heatmap(path, grid=8):\n",
    "    img = load_image(path)\n",
    "    h,w,_ = img.shape\n",
    "    heat = np.zeros((grid,grid))\n",
    "\n",
    "    for i in range(grid):\n",
    "        for j in range(grid):\n",
    "            y1 = int(i*h/grid); y2 = int((i+1)*h/grid)\n",
    "            x1 = int(j*w/grid); x2 = int((j+1)*w/grid)\n",
    "            patch = img[y1:y2,x1:x2]\n",
    "            res = extract_noise_residual(patch)\n",
    "            heat[i,j] = np.std(res)\n",
    "\n",
    "    heat = cv2.resize(heat,(w,h))\n",
    "    return heat\n",
    "\n",
    "# ================= REPORT GENERATOR =================\n",
    "def generate_report(path,vector,cls,ai,tamper,risk):\n",
    "    report = {\n",
    "        \"file\": path,\n",
    "        \"timestamp\": str(datetime.now()),\n",
    "        \"classification\": cls,\n",
    "        \"ai_score\": ai,\n",
    "        \"tamper_score\": tamper,\n",
    "        \"fraud_risk\": risk,\n",
    "        \"forensic_vector\": vector\n",
    "    }\n",
    "\n",
    "    name = path.split('/')[-1].split('.')[0]\n",
    "    with open(f\"{name}_forensic_report.json\",\"w\") as f:\n",
    "        json.dump(report,f,indent=4)\n",
    "\n",
    "    return report\n",
    "\n",
    "# ================= PIPELINE =================\n",
    "def full_forensic_pipeline(path):\n",
    "    img = load_image(path)\n",
    "    vector = forensic_vector(img,path)\n",
    "    cls, ai, tamper = multi_class_engine(vector)\n",
    "    risk = fraud_risk_score(ai,tamper)\n",
    "    heat = region_heatmap(path)\n",
    "    report = generate_report(path,vector,cls,ai,tamper,risk)\n",
    "    return vector, cls, ai, tamper, risk, heat, report\n",
    "\n",
    "# ================= VISUAL =================\n",
    "def visualize_all(path, heat):\n",
    "    img = load_image(path)\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('AI/Tamper Heatmap')\n",
    "    plt.imshow(heat, cmap='hot')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Overlay')\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(heat, cmap='hot', alpha=0.4)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# ================= TECHNIQUE-WISE HEATMAPS =================\n",
    "def heatmap_noise(path):\n",
    "    img = load_image(path)\n",
    "    res = extract_noise_residual(img)\n",
    "    norm = cv2.normalize(np.abs(res), None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def heatmap_edges(path):\n",
    "    img = load_image(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = sobel(gray)\n",
    "    norm = cv2.normalize(edges, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def heatmap_frequency(path):\n",
    "    img = load_image(path)\n",
    "    gray = cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY),(256,256))\n",
    "    f = fftshift(fft2(gray))\n",
    "    mag = np.log(np.abs(f)+1)\n",
    "    mag = cv2.resize(mag,(img.shape[1],img.shape[0]))\n",
    "    norm = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def heatmap_entropy(path, grid=8):\n",
    "    img = load_image(path)\n",
    "    h,w,_ = img.shape\n",
    "    heat = np.zeros((grid,grid))\n",
    "    for i in range(grid):\n",
    "        for j in range(grid):\n",
    "            y1=int(i*h/grid); y2=int((i+1)*h/grid)\n",
    "            x1=int(j*w/grid); x2=int((j+1)*w/grid)\n",
    "            patch = img[y1:y2,x1:x2]\n",
    "            heat[i,j] = entropy_score(patch)\n",
    "    heat = cv2.resize(heat,(w,h))\n",
    "    norm = cv2.normalize(heat, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def heatmap_cfa(path, grid=8):\n",
    "    img = load_image(path)\n",
    "    h,w,_ = img.shape\n",
    "    heat = np.zeros((grid,grid))\n",
    "    for i in range(grid):\n",
    "        for j in range(grid):\n",
    "            y1=int(i*h/grid); y2=int((i+1)*h/grid)\n",
    "            x1=int(j*w/grid); x2=int((j+1)*w/grid)\n",
    "            patch = img[y1:y2,x1:x2]\n",
    "            heat[i,j] = cfa_periodicity(patch)\n",
    "    heat = cv2.resize(heat,(w,h))\n",
    "    norm = cv2.normalize(heat, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return norm\n",
    "\n",
    "\n",
    "# ================= VISUALIZATION DASHBOARD =================\n",
    "def visualize_all_heatmaps(path):\n",
    "    img = load_image(path)\n",
    "\n",
    "    h1 = heatmap_noise(path)\n",
    "    h2 = heatmap_edges(path)\n",
    "    h3 = heatmap_frequency(path)\n",
    "    h4 = heatmap_entropy(path)\n",
    "    h5 = heatmap_cfa(path)\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.title('Noise Residual Heatmap')\n",
    "    plt.imshow(h1, cmap='hot')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.title('Edge Inconsistency Heatmap')\n",
    "    plt.imshow(h2, cmap='hot')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.title('Frequency Anomaly Heatmap')\n",
    "    plt.imshow(h3, cmap='hot')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.title('Entropy Variation Heatmap')\n",
    "    plt.imshow(h4, cmap='hot')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.title('CFA Physics Violation Heatmap')\n",
    "    plt.imshow(h5, cmap='hot')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"FULL FORENSIC SYSTEM READY + TECHNIQUE HEATMAPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test_image.png\"\n",
    "\n",
    "visualize_all_heatmaps(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8054a121",
   "metadata": {},
   "source": [
    "Batch_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"data\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        path = os.path.join(data_dir, file)\n",
    "\n",
    "        try:\n",
    "            vector, cls, ai, tamper, risk, heat, report = full_forensic_pipeline(path)\n",
    "\n",
    "            print(\"=\"*60)\n",
    "            print(\"File:\", file)\n",
    "            print(\"Classification:\", cls)\n",
    "            print(\"AI Score:\", ai)\n",
    "            print(\"Tamper Score:\", tamper)\n",
    "            print(\"Fraud Risk:\", risk)\n",
    "            print(\"Report Generated:\", f\"{file.split('.')[0]}_forensic_report.json\")\n",
    "\n",
    "            results.append({\n",
    "                \"file\": file,\n",
    "                \"classification\": cls,\n",
    "                \"ai_score\": ai,\n",
    "                \"tamper_score\": tamper,\n",
    "                \"fraud_risk\": risk\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"❌ Error processing:\", file, \"->\", str(e))\n",
    "\n",
    "print(\"\\n✅ Batch Processing Completed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
